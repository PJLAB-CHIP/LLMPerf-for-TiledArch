{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from gemm_tiling import gemm_tiling_input_stationary, gemm_tiling_weight_stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前batch size=1时类似，\n",
    "\n",
    "对于weight stationary来说，fuse qkv没太大变化\n",
    "\n",
    "但是对于input stationary来说，fuse qkv会有很大的提升，因为提高了input 的复用率。\n",
    "\n",
    "下面分析两个 FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN Up analysis, B=1\n",
      "FFN Up, M=4096, K=4096, N=11008, B=1, tile_m=64, tile_n=64, stationary: input, utilization=73.26%\n",
      "FFN Up, M=4096, K=4096, N=11008, B=1, tile_m=128, tile_n=32, stationary: input, utilization=88.14%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "FFN Up, M=4096, K=4096, N=11008, B=1, tile_m=256, tile_n=32, stationary: input, utilization=86.34%\n",
      "FFN Up, M=4096, K=4096, N=11008, B=1, tile_m=32, tile_n=128, stationary: weight, utilization=72.84%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "FFN Up, M=4096, K=4096, N=11008, B=1, tile_m=32, tile_n=256, stationary: weight, utilization=71.53%\n"
     ]
    }
   ],
   "source": [
    "# =============== FNN Up  ===================\n",
    "# FFN Gate 与 FFN Up是完全同样的size的计算，这里不列出了\n",
    "M, K, N = 4096, 4096, 11008\n",
    "B = 1\n",
    "\n",
    "print(f\"FFN Up analysis, B={B}\")\n",
    "\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 256\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 256\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为 FFN up是升维，N的维度很高11008，所以input stationary的性能会比weight stationary好很多\n",
    "\n",
    "下面分析batch size的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFN Up analysis, B=32\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=64, tile_n=64, stationary: input, utilization=76.15%\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=128, tile_n=32, stationary: input, utilization=91.15%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=256, tile_n=32, stationary: input, utilization=91.03%\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=32, tile_n=128, stationary: weight, utilization=88.94%\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=64, tile_n=64, stationary: weight, utilization=76.15%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.031250 MB, > SRAM 3.0 MB\n",
      "Error: total size without input buffer 3.531250 MB  is smaller than SRAM size 3.0 MB\n",
      "=========memory anylasis ===================\n",
      "+-------------------+--------------------------+\n",
      "|        var        |         mem (MB)         |\n",
      "+-------------------+--------------------------+\n",
      "|    input_size     | 0.500000 * 2 =  1.000000 |\n",
      "|    weight_size    | 1.000000 * 3 =  3.000000 |\n",
      "|    output_size    | 0.015625 * 2 =  0.031250 |\n",
      "|    total_size     |         3.531250         |\n",
      "| input_load_iters  |            11            |\n",
      "| weight_load_iters |            64            |\n",
      "+-------------------+--------------------------+\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=128, tile_n=64, stationary: weight, utilization=0.00%\n",
      "FFN Up, M=4096, K=4096, N=11008, B=32, tile_m=8, tile_n=128, stationary: weight, utilization=88.76%\n"
     ]
    }
   ],
   "source": [
    "M, K, N = 4096, 4096, 11008\n",
    "B = 32\n",
    "print(f\"FFN Up analysis, B={B}\")\n",
    "\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 256\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 8\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"FFN Up, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

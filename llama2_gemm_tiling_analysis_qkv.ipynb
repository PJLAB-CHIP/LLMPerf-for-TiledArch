{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from gemm_tiling import gemm_tiling_input_stationary, gemm_tiling_weight_stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV projection, M=4096, K=4096, N=4096, B=1, tile_m=64, tile_n=64, stationary: input, utilization=70.14%\n",
      "QKV projection, M=4096, K=4096, N=4096, B=1, tile_m=128, tile_n=32, stationary: input, utilization=76.97%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "QKV projection, M=4096, K=4096, N=4096, B=1, tile_m=256, tile_n=32, stationary: input, utilization=73.38%\n",
      "QKV projection, M=4096, K=4096, N=4096, B=1, tile_m=32, tile_n=128, stationary: weight, utilization=76.97%\n"
     ]
    }
   ],
   "source": [
    "# =============== QKV projection  ===================\n",
    "M, K , N = 4096, 4096, 4096\n",
    "QKV = 1   # QKV = 3, if fuse q k v into one matrix\n",
    "N = N * QKV\n",
    "B = 1\n",
    "\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 256\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过tuning不同的tile_m，tile_n可以得到不同的性能结果\n",
    "\n",
    "因为 M=K=N，所以input stationary和output stationary 可以设置相反的tile_m和tile_n，从而得到完全一样的性能\n",
    "\n",
    "下面分析 q、k、v是否融合的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV projection, QKV=3, fuse q k v into one matrix\n",
      "QKV projection, M=4096, K=4096, N=12288, B=1, tile_m=64, tile_n=64, stationary: input, utilization=75.21%\n",
      "QKV projection, M=4096, K=4096, N=12288, B=1, tile_m=128, tile_n=32, stationary: input, utilization=90.93%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "QKV projection, M=4096, K=4096, N=12288, B=1, tile_m=256, tile_n=32, stationary: input, utilization=89.21%\n",
      "QKV projection, M=4096, K=4096, N=12288, B=1, tile_m=32, tile_n=128, stationary: weight, utilization=81.31%\n"
     ]
    }
   ],
   "source": [
    "# =============== QKV projection  ===================\n",
    "M, K , N = 4096, 4096, 4096\n",
    "QKV = 3   # QKV = 3, if fuse q k v into one matrix\n",
    "N = N * QKV\n",
    "B = 1\n",
    "print(\"QKV projection, QKV=3, fuse q k v into one matrix\")\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 256\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，对于weight stationary来说，fuse qkv没太大变化，但是对于input stationary来说，fuse qkv会有很大的提升，因为提高了input 的复用率。\n",
    "\n",
    "下面分析batch size的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV projection, batch size analysis, B=16\n",
      "QKV projection, M=4096, K=4096, N=4096, B=16, tile_m=64, tile_n=64, stationary: input, utilization=77.48%\n",
      "QKV projection, M=4096, K=4096, N=4096, B=16, tile_m=128, tile_n=32, stationary: input, utilization=83.22%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "QKV projection, M=4096, K=4096, N=4096, B=16, tile_m=256, tile_n=32, stationary: input, utilization=82.82%\n",
      "QKV projection, M=4096, K=4096, N=4096, B=16, tile_m=32, tile_n=128, stationary: weight, utilization=98.16%\n"
     ]
    }
   ],
   "source": [
    "# =============== QKV projection  ===================\n",
    "M, K , N = 4096, 4096, 4096\n",
    "QKV = 1   # QKV = 3, if fuse q k v into one matrix\n",
    "N = N * QKV\n",
    "B = 16\n",
    "print(f\"QKV projection, batch size analysis, B={B}\")\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 256\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，对于weight stationary来说，batch size的增大影响很大，batch size增大明显提高了weight的复用率\n",
    "\n",
    "而对于input stationary来说，batch size的增大影响不大\n",
    "\n",
    "下面在batch size基础上分析qkv是否融合的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV projection, fuse QKV, batch size analysis, B=16\n",
      "QKV projection, M=4096, K=4096, N=12288, B=16, tile_m=64, tile_n=64, stationary: input, utilization=77.84%\n",
      "QKV projection, M=4096, K=4096, N=12288, B=16, tile_m=128, tile_n=32, stationary: input, utilization=93.70%\n",
      "Warning: using defautl buffer strategy, nedd total memory 4.781250 MB, > SRAM 3.0 MB\n",
      "Warning: change input buffer strategy to input_buffer_num =  1\n",
      "QKV projection, M=4096, K=4096, N=12288, B=16, tile_m=256, tile_n=32, stationary: input, utilization=93.53%\n",
      "QKV projection, M=4096, K=4096, N=12288, B=16, tile_m=32, tile_n=128, stationary: weight, utilization=98.58%\n"
     ]
    }
   ],
   "source": [
    "# =============== QKV projection  ===================\n",
    "M, K , N = 4096, 4096, 4096\n",
    "QKV = 3   # QKV = 3, if fuse q k v into one matrix\n",
    "N = N * QKV\n",
    "B = 16\n",
    "print(f\"QKV projection, fuse QKV, batch size analysis, B={B}\")\n",
    "tile_m = 64\n",
    "tile_n = 64\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 128\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 256\n",
    "tile_n = 32\n",
    "utilization = gemm_tiling_input_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: input, utilization={utilization:.2f}%\")\n",
    "\n",
    "tile_m = 32\n",
    "tile_n = 128\n",
    "utilization = gemm_tiling_weight_stationary(B, M, K, N, tile_m, tile_n, print_details=False)\n",
    "print(f\"QKV projection, M={M}, K={K}, N={N}, B={B}, tile_m={tile_m}, tile_n={tile_n}, stationary: weight, utilization={utilization:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和之前batch size=1时类似，\n",
    "\n",
    "对于weight stationary来说，fuse qkv没太大变化\n",
    "\n",
    "但是对于input stationary来说，fuse qkv会有很大的提升，因为提高了input 的复用率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
